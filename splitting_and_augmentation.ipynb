{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed African Violet (Saintpaulia ionantha) with 231 original images.\n",
      "Processed Aloe Vera with 171 original images.\n",
      "Processed Anthurium (Anthurium andraeanum) with 316 original images.\n",
      "Processed Areca Palm (Dypsis lutescens) with 132 original images.\n",
      "Processed Asparagus Fern (Asparagus setaceus) with 115 original images.\n",
      "Processed Begonia (Begonia spp.) with 158 original images.\n",
      "Processed Bird of Paradise (Strelitzia reginae) with 123 original images.\n",
      "Processed Birds Nest Fern (Asplenium nidus) with 203 original images.\n",
      "Processed Boston Fern (Nephrolepis exaltata) with 208 original images.\n",
      "Processed Calathea with 230 original images.\n",
      "Processed Cast Iron Plant (Aspidistra elatior) with 186 original images.\n",
      "Processed Chinese evergreen (Aglaonema) with 358 original images.\n",
      "Processed Chinese Money Plant (Pilea peperomioides) with 265 original images.\n",
      "Processed Christmas Cactus (Schlumbergera bridgesii) with 211 original images.\n",
      "Processed Chrysanthemum with 145 original images.\n",
      "Processed Ctenanthe with 233 original images.\n",
      "Processed Daffodils (Narcissus spp.) with 290 original images.\n",
      "Processed Dracaena with 182 original images.\n",
      "Processed Dumb Cane (Dieffenbachia spp.) with 370 original images.\n",
      "Processed Elephant Ear (Alocasia spp.) with 226 original images.\n",
      "Processed English Ivy (Hedera helix) with 163 original images.\n",
      "Processed Hyacinth (Hyacinthus orientalis) with 221 original images.\n",
      "Processed Iron Cross begonia (Begonia masoniana) with 183 original images.\n",
      "Processed Jade plant (Crassula ovata) with 243 original images.\n",
      "Processed Kalanchoe with 89 original images.\n",
      "Processed Lilium (Hemerocallis) with 334 original images.\n",
      "Processed Lily of the valley (Convallaria majalis) with 281 original images.\n",
      "Processed Money Tree (Pachira aquatica) with 251 original images.\n",
      "Processed Monstera Deliciosa (Monstera deliciosa) with 376 original images.\n",
      "Processed Orchid with 162 original images.\n",
      "Processed Parlor Palm (Chamaedorea elegans) with 227 original images.\n",
      "Processed Peace lily with 264 original images.\n",
      "Processed Poinsettia (Euphorbia pulcherrima) with 212 original images.\n",
      "Processed Polka Dot Plant (Hypoestes phyllostachya) with 238 original images.\n",
      "Processed Ponytail Palm (Beaucarnea recurvata) with 137 original images.\n",
      "Processed Pothos (Ivy arum) with 170 original images.\n",
      "Processed Prayer Plant (Maranta leuconeura) with 279 original images.\n",
      "Processed Rattlesnake Plant (Calathea lancifolia) with 217 original images.\n",
      "Processed Rubber Plant (Ficus elastica) with 203 original images.\n",
      "Processed Sago Palm (Cycas revoluta) with 141 original images.\n",
      "Processed Schefflera with 223 original images.\n",
      "Processed Snake plant (Sanseviera) with 276 original images.\n",
      "Processed Tradescantia with 230 original images.\n",
      "Processed Tulip with 237 original images.\n",
      "Processed Venus Flytrap with 138 original images.\n",
      "Processed Yucca with 45 original images.\n",
      "Processed ZZ Plant (Zamioculcas zamiifolia) with 301 original images.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "def add_salt_and_pepper_noise(image, amount=0.04, salt_vs_pepper=0.5):\n",
    "    \"\"\"Add salt-and-pepper noise to an image.\"\"\"\n",
    "    image = image.convert('RGB')\n",
    "    img_array = np.array(image)\n",
    "    h, w = img_array.shape[:2]\n",
    "    num_salt = int(amount * h * w * salt_vs_pepper)\n",
    "    num_pepper = int(amount * h * w * (1 - salt_vs_pepper))\n",
    "\n",
    "    # Add salt (white)\n",
    "    coords = [np.random.randint(0, i - 1, num_salt) for i in img_array.shape[:2]]\n",
    "    img_array[coords[0], coords[1]] = 255\n",
    "\n",
    "    # Add pepper (black)\n",
    "    coords = [np.random.randint(0, i - 1, num_pepper) for i in img_array.shape[:2]]\n",
    "    img_array[coords[0], coords[1]] = 0\n",
    "\n",
    "    return Image.fromarray(img_array)\n",
    "\n",
    "def add_gaussian_noise(image, mean=0, std=0.05):\n",
    "    \"\"\"Add Gaussian noise to an image.\"\"\"\n",
    "    image = image.convert('RGB')\n",
    "    img_array = np.array(image) / 255.0  # Normalize to [0, 1]\n",
    "    noise = np.random.normal(mean, std, img_array.shape)\n",
    "    noisy_img_array = img_array + noise\n",
    "    noisy_img_array = np.clip(noisy_img_array, 0, 1)  # Ensure values are between 0 and 1\n",
    "    return Image.fromarray((noisy_img_array * 255).astype(np.uint8))\n",
    "\n",
    "def random_zoom(image, crop_percentage=0.1):\n",
    "    \"\"\"Randomly zoom into an image by cropping a percentage from each side.\"\"\"\n",
    "    width, height = image.size\n",
    "    \n",
    "    # Calculate the cropping area\n",
    "    left = int(width * crop_percentage)\n",
    "    top = int(height * crop_percentage)\n",
    "    right = width - int(width * crop_percentage)\n",
    "    bottom = height - int(height * crop_percentage)\n",
    "    \n",
    "    # Crop the image\n",
    "    cropped_img = image.crop((left, top, right, bottom))\n",
    "    \n",
    "    # Resize back to original size\n",
    "    return cropped_img.resize((width, height), Image.Resampling.LANCZOS)\n",
    "\n",
    "\n",
    "def adjust_brightness_contrast(image, brightness_factor=1.2, contrast_factor=1.2):\n",
    "    \"\"\"Adjust the brightness and contrast of an image.\"\"\"\n",
    "    image = image.convert(\"RGB\")  # Ensure the image is in RGB mode\n",
    "    enhancer = ImageEnhance.Brightness(image)\n",
    "    image = enhancer.enhance(brightness_factor)\n",
    "    \n",
    "    enhancer = ImageEnhance.Contrast(image)\n",
    "    image = enhancer.enhance(contrast_factor)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def add_gaussian_blur(image, radius=2):\n",
    "    # Ensure the input is a valid image\n",
    "    if not isinstance(image, Image.Image):\n",
    "        raise ValueError(\"The input is not a valid PIL Image object.\")\n",
    "    \n",
    "    # Convert non-RGB modes to RGB\n",
    "    if image.mode not in ('RGB', 'RGBA'):\n",
    "        image = image.convert('RGB')\n",
    "    \n",
    "    # Apply Gaussian blur\n",
    "    return image.filter(ImageFilter.GaussianBlur(radius))\n",
    "\n",
    "def darken(image, factor=0.6):\n",
    "    # Ensure image is in RGB mode\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "    \n",
    "    enhancer = ImageEnhance.Brightness(image)\n",
    "    return enhancer.enhance(factor)\n",
    "\n",
    "\n",
    "\n",
    "MAX_CLASS_SIZE = 500\n",
    "\n",
    "def apply_augmentation_to_class(class_images, class_size, class_name):\n",
    "    augmented_images = []\n",
    "    \n",
    "    if class_size >= MAX_CLASS_SIZE:\n",
    "        print(f\"Skipping augmentation for {class_name} as class size has reached the limit of {MAX_CLASS_SIZE}.\")\n",
    "        return augmented_images  # No augmentation for this class\n",
    "\n",
    "    for img_info in class_images:\n",
    "        img, original_image_name = img_info\n",
    "        count = 0 \n",
    "        if class_size >= MAX_CLASS_SIZE:\n",
    "            print(f\"Reached max class size for {class_name}, stopping augmentation.\")\n",
    "            break  # Stop augmentation if class size reaches the limit\n",
    "        \n",
    "        # original_image_name = os.path.splitext(os.path.basename(img.filename))[0]\n",
    "\n",
    "        if class_size < 50:\n",
    "            # Apply all augmentations and combinations of two\n",
    "            augmented_images.append((add_salt_and_pepper_noise(img), f'{original_image_name}_salt_and_pepper_noise'))\n",
    "            augmented_images.append((add_gaussian_noise(img), f'{original_image_name}_gaussian_noise'))\n",
    "            augmented_images.append((random_zoom(img), f'{original_image_name}_random_zoom'))\n",
    "            augmented_images.append((adjust_brightness_contrast(img), f'{original_image_name}_brightness_contrast'))\n",
    "\n",
    "            # Convert to RGB before applying Gaussian blur\n",
    "            img_rgb = img.convert(\"RGB\")\n",
    "            augmented_images.append((img_rgb.filter(ImageFilter.GaussianBlur(radius=2)), f'{original_image_name}_gaussian_blur'))\n",
    "\n",
    "            augmented_images.append((darken(img), f'{original_image_name}_darken'))  # Darken the image\n",
    "\n",
    "            # Apply combinations of two augmentations\n",
    "            augmented_images.append((add_gaussian_noise(random_zoom(img)), f'{original_image_name}_gaussian_noise_zoom'))\n",
    "            augmented_images.append((add_salt_and_pepper_noise(adjust_brightness_contrast(img)), f'{original_image_name}_salt_brightness_contrast'))\n",
    "\n",
    "\n",
    "        elif 50 <= class_size < 100:\n",
    "            # Apply all augmentations and combinations of two\n",
    "            augmented_images.append((add_salt_and_pepper_noise(img), f'{original_image_name}_salt_and_pepper_noise'))\n",
    "            augmented_images.append((add_gaussian_noise(img), f'{original_image_name}_gaussian_noise'))\n",
    "            \n",
    "            augmented_images.append((adjust_brightness_contrast(img), f'{original_image_name}_brightness_contrast'))\n",
    "            augmented_images.append((img.filter(ImageFilter.GaussianBlur(radius=2)), f'{original_image_name}_gaussian_blur'))\n",
    "        \n",
    "        \n",
    "            \n",
    "        elif class_size>= 100:\n",
    "            augmented_images.append((add_salt_and_pepper_noise(img), f'{original_image_name}_salt_and_pepper_noise'))\n",
    "            augmented_images.append((add_gaussian_noise(img), f'{original_image_name}_gaussian_noise'))\n",
    "            augmented_images.append((img.filter(ImageFilter.GaussianBlur(radius=2)), f'{original_image_name}_gaussian_blur'))\n",
    "            augmented_images.append((adjust_brightness_contrast(img), f'{original_image_name}_brightness_contrast'))\n",
    "            class_size += 4\n",
    "            if class_size >= MAX_CLASS_SIZE: break\n",
    "        \n",
    "        '''if class_size >= MAX_CLASS_SIZE:\n",
    "            print(f\"Reached max class size for {class_name}, stopping augmentation.\")\n",
    "            break'''\n",
    "        \n",
    "    return augmented_images\n",
    "\n",
    "def save_augmented_images(class_images, augmented_images, class_path):\n",
    "    for img, img_name in augmented_images:\n",
    "        # Convert image to RGB before saving if not already in RGB mode\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "        \n",
    "        img.save(f\"{class_path}/{img_name}.jpg\", 'JPEG')\n",
    "# Example usage\n",
    "def process_images_in_dataset(train_dir):\n",
    "    class_names = os.listdir(train_dir)\n",
    "    \n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(train_dir, class_name)\n",
    "        \n",
    "        if os.path.isdir(class_path):\n",
    "            # Include both Image objects and their original names as tuples\n",
    "            class_images = [\n",
    "                (Image.open(os.path.join(class_path, img)).convert('RGB'), os.path.splitext(img)[0])\n",
    "                for img in os.listdir(class_path) \n",
    "                if img.lower().endswith(('png', 'jpg', 'jpeg'))\n",
    "            ]\n",
    "            class_size = len(class_images)\n",
    "            # Apply augmentations based on class size\n",
    "            augmented_images = apply_augmentation_to_class(class_images, class_size, class_name)\n",
    "            \n",
    "            # Save augmented images\n",
    "            save_augmented_images(class_images, augmented_images, class_path)\n",
    "            \n",
    "            print(f\"Processed {class_name} with {class_size} original images.\")\n",
    "\n",
    "# Run the processing\n",
    "train_dir = r\"C:\\Users\\eliza\\OneDrive\\Desktop\\4-cu kurs\\FIRST SEM\\AI\\project\\for_test\\train\"\n",
    "process_images_in_dataset(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
